from langchain_cohere import ChatCohere
from langchain_core.messages import HumanMessage, AIMessage, BaseMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_core.chat_history import BaseChatMessageHistory
import pickle
import os
import PyPDF2
from collections import deque
from dotenv import load_dotenv

def env(key: str, default=None):
    return os.getenv(key, default)

COHERE_API_KEY = env("COHERE_API_KEY")
MEMORY_FILE = "chatbot_memory.pkl"
PDF_FILE = "sotaysinhvien2025.pdf"

# Äá»c ná»™i dung PDF
def load_pdf_content(pdf_path):
    """TrÃ­ch xuáº¥t ná»™i dung tá»« file PDF"""
    text = ""
    try:
        with open(pdf_path, "rb") as file:
            pdf_reader = PyPDF2.PdfReader(file)
            for page in pdf_reader.pages:
                text += page.extract_text() + "\n"
        print(f"âœ“ ÄÃ£ táº£i PDF: {pdf_path}\n")
    except Exception as e:
        print(f"âœ— Lá»—i khi Ä‘á»c PDF: {e}\n")
    return text

# Custom chat history class Ä‘á»ƒ lÆ°u vÃ o pickle
class PersistentChatHistory(BaseChatMessageHistory):
    def __init__(self, messages=None):
        self.messages = list(messages) if messages else []
    
    def add_message(self, message: BaseMessage) -> None:
        self.messages.append(message)
    
    def clear(self) -> None:
        self.messages = []

# Táº£i ná»™i dung PDF
pdf_content = load_pdf_content(PDF_FILE) if os.path.exists(PDF_FILE) else ""

# Khá»Ÿi táº¡o LLM
llm = ChatCohere(model="command-a-03-2025", cohere_api_key=COHERE_API_KEY)

# Táº£i hoáº·c táº¡o má»›i chat history
if os.path.exists(MEMORY_FILE):
    try:
        with open(MEMORY_FILE, "rb") as f:
            chat_history = pickle.load(f)
        # Kiá»ƒm tra xem cÃ³ pháº£i PersistentChatHistory khÃ´ng
        if not isinstance(chat_history, PersistentChatHistory):
            chat_history = PersistentChatHistory()
        print("ğŸ“‚ Táº£i lá»‹ch sá»­ há»™i thoáº¡i cÅ©\n")
    except:
        chat_history = PersistentChatHistory()
        print("âœ¨ Báº¯t Ä‘áº§u cuá»™c trÃ² chuyá»‡n má»›i\n")
else:
    chat_history = PersistentChatHistory()
    print("âœ¨ Báº¯t Ä‘áº§u cuá»™c trÃ² chuyá»‡n má»›i\n")

# Táº¡o prompt template vá»›i ná»™i dung PDF
# Escape curly braces Ä‘á»ƒ trÃ¡nh lá»—i template variable
escaped_pdf = pdf_content.replace("{", "{{").replace("}", "}}")
system_message = f"""Báº¡n lÃ  má»™t trá»£ lÃ½ há»¯u Ã­ch. Sá»­ dá»¥ng thÃ´ng tin tá»« tÃ i liá»‡u sau Ä‘á»ƒ tráº£ lá»i cÃ¢u há»i:

{escaped_pdf}

Náº¿u báº¡n khÃ´ng tÃ¬m tháº¥y thÃ´ng tin cáº§n thiáº¿t trong tÃ i liá»‡u, hÃ£y cho biáº¿t rÃµ Ä‘iá»u Ä‘Ã³."""

prompt = ChatPromptTemplate.from_messages([
    ("system", system_message),
    MessagesPlaceholder(variable_name="history"),
    ("human", "{input}")
])

chain = prompt | llm

print("ğŸ¤– Chatbot Console")
print("GÃµ 'quit' hoáº·c 'exit' Ä‘á»ƒ thoÃ¡t\n")

try:
    while True:
        user_input = input("Báº¡n: ").strip()
        
        if user_input.lower() in ["quit", "exit"]:
            # LÆ°u lá»‹ch sá»­ trÆ°á»›c khi thoÃ¡t
            with open(MEMORY_FILE, "wb") as f:
                pickle.dump(chat_history, f)
            print("ğŸ’¾ ÄÃ£ lÆ°u lá»‹ch sá»­ há»™i thoáº¡i")
            print("Táº¡m biá»‡t! ğŸ‘‹")
            break
        
        if not user_input:
            continue
        
        # Gá»i chain vá»›i input vÃ  history
        user_message = HumanMessage(content=user_input)
        chat_history.add_message(user_message)
        
        response = chain.invoke({
            "input": user_input,
            "history": chat_history.messages
        })
        
        ai_message = AIMessage(content=response.content)
        chat_history.add_message(ai_message)
        print(f"Bot: {response.content}\n")
except KeyboardInterrupt:
    # LÆ°u lá»‹ch sá»­ náº¿u bá»‹ interrupt (Ctrl+C)
    with open(MEMORY_FILE, "wb") as f:
        pickle.dump(chat_history, f)
    print("\nğŸ’¾ ÄÃ£ lÆ°u lá»‹ch sá»­ há»™i thoáº¡i")
    print("Táº¡m biá»‡t! ğŸ‘‹")
